{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import array_to_img, img_to_array, load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (128, 128)\n",
    "cats_tr = [join('Data/Train/Cats', f) for f in listdir('Data/Train/Cats')]\n",
    "dogs_tr = [join('Data/Train/Dogs', f) for f in listdir('Data/Train/Dogs')]\n",
    "cats_te = [join('Data/Test/Cats', f) for f in listdir('Data/Test/Cats')]\n",
    "dogs_te = [join('Data/Test/Dogs', f) for f in listdir('Data/Test/Dogs')]\n",
    "dogs_train_x = np.array([img_to_array(load_img(image).resize(size)) for image in dogs_tr])\n",
    "dogs_train_y = np.array([1 for image in dogs_tr])\n",
    "cats_train_x = np.array([img_to_array(load_img(image).resize(size)) for image in cats_tr])\n",
    "cats_train_y = np.array([0 for image in cats_tr]) #0 for cats\n",
    "dogs_test_x = np.array([img_to_array(load_img(image).resize(size)) for image in dogs_te])\n",
    "dogs_test_y = np.array([1 for image in dogs_te]) #1 for dogs\n",
    "cats_test_x = np.array([img_to_array(load_img(image).resize(size)) for image in cats_te])\n",
    "cats_test_y = np.array([0 for image in cats_te])\n",
    "x_train = np.append(cats_train_x, dogs_train_x, axis=0)\n",
    "x_test = np.append(cats_test_x, dogs_test_x, axis = 0)\n",
    "y_train = np.append(cats_train_y, dogs_train_y)\n",
    "y_test = np.append(cats_test_y, dogs_test_y)\n",
    "x_train, y_train = shuffle(x_train, y_train, random_state=0)\n",
    "x_test, y_test = shuffle(x_test, y_test, random_state=0)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet without Augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_1 = keras.applications.ResNet50(\n",
    "    weights = './resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "    input_shape = (size[0], size[1], 3),\n",
    "    include_top = False\n",
    ")\n",
    "base_model_1.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning without Augment ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = keras.layers.Input(shape=(size[0], size[0], 3))\n",
    "normaled_1 = keras.layers.BatchNormalization()(input_1)\n",
    "out_1_1 = base_model_1(normaled_1, training = False)\n",
    "out_2_1 = keras.layers.Flatten()(out_1_1)\n",
    "classifier_1 = keras.Sequential([\n",
    "    keras.layers.Dense(15, activation = 'relu', name = 'classifier_1'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(rate = 0.2),\n",
    "    keras.layers.Dense(15, activation = 'relu', name = 'classifier_2'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(rate = 0.2),\n",
    "    keras.layers.Dense(1, activation = 'sigmoid', name = 'class'),]\n",
    ")\n",
    "output_1 = classifier_1(out_2_1)\n",
    "model_1 = keras.Model(input_1, output_1)\n",
    "model_1.compile(optimizer = keras.optimizers.legacy.SGD(learning_rate = 0.1, momentum = 0.9, decay = 0.002), loss = 'binary_crossentropy', metrics = [keras.metrics.BinaryAccuracy()])\n",
    "history_1 = model_1.fit(x_train, y_train, batch_size = 10, epochs = 25, validation_data = (x_valid, y_valid), shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning ResNet without Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_1.trainable = False\n",
    "for layer in range(1, 10):\n",
    "    base_model_1.layers[-1*layer].trainable = True\n",
    "model_1.compile(optimizer = keras.optimizers.legacy.SGD(learning_rate = 0.1, momentum = 0.9, decay = 0.002), loss = 'binary_crossentropy', metrics = [keras.metrics.BinaryAccuracy()])\n",
    "history_tune_1 = model_1.fit(x_train, y_train, batch_size = 10, epochs = 25, validation_data = (x_valid, y_valid), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.evaluate(x_test, y_test, batch_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment = keras.Sequential([\n",
    "    keras.layers.RandomFlip('horizontal'),\n",
    "    keras.layers.RandomRotation(factor=1/6.0),\n",
    "    keras.layers.RandomZoom(height_factor = 0.25, width_factor = 0.25)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50 for Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.ResNet50(\n",
    "    weights = './resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "    input_shape = (size[0], size[1], 3),\n",
    "    include_top = False\n",
    ")\n",
    "base_model.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning with Augment ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = keras.layers.Input(shape=(size[0], size[0], 3))\n",
    "normaled = keras.layers.BatchNormalization()(input)\n",
    "out_0 = augment(normaled)\n",
    "out_1 = base_model(out_0, training = False)\n",
    "out_2 = keras.layers.Flatten()(out_1)\n",
    "classifier = keras.Sequential([\n",
    "    keras.layers.Dense(15, activation = 'relu', name = 'classifier_1'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(rate = 0.2),\n",
    "    keras.layers.Dense(15, activation = 'relu', name = 'classifier_2'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    #keras.layers.Dropout(rate = 0.2),\n",
    "    keras.layers.Dense(1, activation = 'sigmoid', name = 'class'),]\n",
    ")\n",
    "output = classifier(out_2)\n",
    "model = keras.Model(input, output)\n",
    "model.compile(optimizer = keras.optimizers.legacy.SGD(learning_rate = 0.1, momentum = 0.9, decay = 0.002), loss = 'binary_crossentropy', metrics = [keras.metrics.BinaryAccuracy()])\n",
    "history = model.fit(x_train, y_train, batch_size = 10, epochs = 25, validation_data = (x_valid, y_valid), shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning ResNet with Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "for layer in range(1, 10):\n",
    "    base_model.layers[-1*layer].trainable = True\n",
    "model.compile(optimizer = keras.optimizers.legacy.SGD(learning_rate = 0.1, momentum = 0.9, decay = 0.002), loss = 'binary_crossentropy', metrics = [keras.metrics.BinaryAccuracy()])\n",
    "history_tune = model.fit(x_train, y_train, batch_size = 10, epochs = 25, validation_data = (x_valid, y_valid), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_val_binary_accuracy = history_1.history['val_binary_accuracy'] + history_tune_1.history['val_binary_accuracy']\n",
    "resnet_binary_accuracy = history_1.history['binary_accuracy'] + history_tune_1.history['binary_accuracy']\n",
    "resnet_val_binary_accuracy_aug = history.history['val_binary_accuracy'] + history_tune.history['val_binary_accuracy']\n",
    "resnet_binary_accuracy_aug = history.history['binary_accuracy'] + history_tune.history['binary_accuracy']\n",
    "\n",
    "resnet_val_binary_loss = history_1.history['val_loss'] + history_tune_1.history['val_loss']\n",
    "resnet_binary_loss = history_1.history['loss'] + history_tune_1.history['loss']\n",
    "resnet_val_binary_loss_aug = history.history['val_loss'] + history_tune.history['val_loss']\n",
    "resnet_binary_loss_aug = history.history['loss'] + history_tune.history['loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy for ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize = (15, 7.5))\n",
    "ax1.plot(resnet_val_binary_accuracy_aug)\n",
    "ax1.plot(resnet_binary_accuracy_aug)\n",
    "ax1.set(xlabel = 'num of Epochs', ylabel = 'Accuracy')\n",
    "ax1.set_title('Accuracy for Augmented Data and ResNet50')\n",
    "ax2.plot(resnet_val_binary_accuracy)\n",
    "ax2.plot(resnet_binary_accuracy)\n",
    "ax2.set(xlabel = 'num of Epochs', ylabel = 'Accuracy')\n",
    "ax2.set_title('Accuracy for Unaugmented Data and ResNet50')\n",
    "ax1.legend(labels=['validation', 'train'])\n",
    "ax2.legend(labels=['validation', 'train'])\n",
    "plt.savefig('res_acc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize = (15, 7.5))\n",
    "ax1.plot(resnet_val_binary_loss_aug)\n",
    "ax1.plot(resnet_binary_loss_aug)\n",
    "ax1.set(xlabel = 'num of Epochs', ylabel = 'Loss')\n",
    "ax1.set_title('Loss for Augmented Data and ResNet50')\n",
    "ax2.plot(resnet_val_binary_loss)\n",
    "ax2.plot(resnet_binary_loss)\n",
    "ax2.set(xlabel = 'num of Epochs', ylabel = 'Loss')\n",
    "ax2.set_title('Loss for Unaugmented Data and ResNet50')\n",
    "ax1.legend(labels=['validation', 'train'])\n",
    "ax2.legend(labels=['validation', 'train'])\n",
    "plt.savefig('res_loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save_weights('res_unaug.h5')\n",
    "model.save_weights('res_aug.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 without Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_1 = keras.applications.VGG16(\n",
    "    weights = 'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "    input_shape = (size[0], size[1], 3),\n",
    "    include_top = False\n",
    ")\n",
    "base_model_1.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning without Augment VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = keras.layers.Input(shape=(size[0], size[0], 3))\n",
    "normaled_1 = keras.layers.BatchNormalization()(input_1)\n",
    "out_1_1 = base_model_1(normaled_1, training = False)\n",
    "out_2_1 = keras.layers.Flatten()(out_1_1)\n",
    "classifier_1 = keras.Sequential([\n",
    "    keras.layers.Dense(15, activation = 'relu', name = 'classifier_1'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(rate = 0.2),\n",
    "    keras.layers.Dense(15, activation = 'relu', name = 'classifier_2'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(rate = 0.2),\n",
    "    keras.layers.Dense(1, activation = 'sigmoid', name = 'class'),]\n",
    ")\n",
    "output_1 = classifier_1(out_2_1)\n",
    "model_1 = keras.Model(input_1, output_1)\n",
    "model_1.compile(optimizer = keras.optimizers.legacy.SGD(learning_rate = 0.1, momentum = 0.9, decay = 0.002), loss = 'binary_crossentropy', metrics = [keras.metrics.BinaryAccuracy()])\n",
    "history_1 = model_1.fit(x_train, y_train, batch_size = 10, epochs = 25, validation_data = (x_valid, y_valid), shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning VGG without Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_1.trainable = False\n",
    "for layer in range(1, 3):\n",
    "    base_model_1.layers[-1*layer].trainable = True\n",
    "model_1.compile(optimizer = keras.optimizers.legacy.SGD(learning_rate = 0.1, momentum = 0.9, decay = 0.002), loss = 'binary_crossentropy', metrics = [keras.metrics.BinaryAccuracy()])\n",
    "history_tune_1 = model_1.fit(x_train, y_train, batch_size = 10, epochs = 25, validation_data = (x_valid, y_valid), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.evaluate(x_test, y_test, batch_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 for Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.VGG16(\n",
    "    weights = 'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "    input_shape = (size[0], size[1], 3),\n",
    "    include_top = False\n",
    ")\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning with Augment VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = keras.layers.Input(shape=(size[0], size[0], 3))\n",
    "normaled = keras.layers.BatchNormalization()(input)\n",
    "out_0 = augment(normaled)\n",
    "out_1 = base_model(out_0, training = False)\n",
    "out_2 = keras.layers.Flatten()(out_1)\n",
    "classifier = keras.Sequential([\n",
    "    keras.layers.Dense(15, activation = 'relu', name = 'classifier_1'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    #keras.layers.Dropout(rate = 0.2),\n",
    "    keras.layers.Dense(15, activation = 'relu', name = 'classifier_2'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    #keras.layers.Dropout(rate = 0.2),\n",
    "    keras.layers.Dense(1, activation = 'sigmoid', name = 'class'),]\n",
    ")\n",
    "output = classifier(out_2)\n",
    "model = keras.Model(input, output)\n",
    "model.compile(optimizer = keras.optimizers.legacy.SGD(learning_rate = 0.1, momentum = 0.9, decay = 0.002), loss = 'binary_crossentropy', metrics = [keras.metrics.BinaryAccuracy()])\n",
    "history = model.fit(x_train, y_train, batch_size = 10, epochs = 25, validation_data = (x_valid, y_valid), shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning VGG with Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "for layer in range(1, 3):\n",
    "    base_model.layers[-1*layer].trainable = True\n",
    "model.compile(optimizer = keras.optimizers.legacy.SGD(learning_rate = 0.1, momentum = 0.9, decay = 0.002), loss = 'binary_crossentropy', metrics = [keras.metrics.BinaryAccuracy()])\n",
    "history_tune = model.fit(x_train, y_train, batch_size = 10, epochs = 25, validation_data = (x_valid, y_valid), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_val_binary_accuracy = history_1.history['val_binary_accuracy'] + history_tune_1.history['val_binary_accuracy']\n",
    "vgg_binary_accuracy = history_1.history['binary_accuracy'] + history_tune_1.history['binary_accuracy']\n",
    "vgg_val_binary_accuracy_aug = history.history['val_binary_accuracy'] + history_tune.history['val_binary_accuracy']\n",
    "vgg_binary_accuracy_aug = history.history['binary_accuracy'] + history_tune.history['binary_accuracy']\n",
    "\n",
    "vgg_val_binary_loss = history_1.history['val_loss'] + history_tune_1.history['val_loss']\n",
    "vgg_binary_loss = history_1.history['loss'] + history_tune_1.history['loss']\n",
    "vgg_val_binary_loss_aug = history.history['val_loss'] + history_tune.history['val_loss']\n",
    "vgg_binary_loss_aug = history.history['loss'] + history_tune.history['loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy for VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize = (15, 7.5))\n",
    "ax1.plot(vgg_val_binary_accuracy)\n",
    "ax1.plot(vgg_binary_accuracy)\n",
    "ax1.set(xlabel = 'num of Epochs', ylabel = 'Accuracy')\n",
    "ax1.set_title('Accuracy for Unaugmented Data and VGG16')\n",
    "ax2.plot(vgg_val_binary_accuracy_aug)\n",
    "ax2.plot(vgg_binary_accuracy_aug)\n",
    "ax2.set(xlabel = 'num of Epochs', ylabel = 'Accuracy')\n",
    "ax2.set_title('Accuracy for augmented Data and VGG16')\n",
    "ax1.legend(labels=['validation', 'train'])\n",
    "ax2.legend(labels=['validation', 'train'])\n",
    "plt.savefig('vgg_acc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize = (15, 7.5))\n",
    "ax1.plot(vgg_val_binary_loss)\n",
    "ax1.plot(vgg_binary_loss)\n",
    "ax1.set(xlabel = 'num of Epochs', ylabel = 'Loss')\n",
    "ax1.set_title('Loss for Unaugmented Data and VGG16')\n",
    "ax2.plot(vgg_val_binary_loss_aug)\n",
    "ax2.plot(vgg_binary_loss_aug)\n",
    "ax2.set(xlabel = 'num of Epochs', ylabel = 'Loss')\n",
    "ax2.set_title('Loss for augmented Data and VGG16')\n",
    "ax1.legend(labels=['validation', 'train'])\n",
    "ax2.legend(labels=['validation', 'train'])\n",
    "plt.savefig('vgg_loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save_weights('vgg_unaug.h5')\n",
    "model.save_weights('vgg_aug.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
